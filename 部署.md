#### 1.配置数据源
使用云坤系统软件iHarbor Rclone将对象存储挂载到本地
https://gitee.com/cstcloud-cnic/iHarborRclone/releases

安装Iharbor_Rclone，进入解压后的目录，执行以下操作安装
```shell
sudo cp rclone /usr/bin/
sudo chown root:root /usr/bin/rclone
sudo chmod 755 /usr/bin/rclone
sudo mkdir -p /usr/local/share/man/man1
sudo cp rclone.1 /usr/local/share/man/man1/
sudo mandb
```

配置netflow对象存储数据源，挂载到本地（/iharbor/mahegu/）
```shell
rclone mount mahegu:mahegu /iharbor/mahegu/ --cache-dir /cache/dir/vfsmout/ --vfs-cache-mode off --allow-non-empty --read-only --daemon
```

#### 2.配置环境

安装基础环境
```shell
pip install -r requirements.txt
```
安装torch_geometric相关依赖
```shell
pip3 install torch_geometric/torch_cluster-1.6.0+pt112cpu-cp310-cp310-linux_x86_64.whl
pip3 install torch_geometric/torch_scatter-2.0.9-cp310-cp310-linux_x86_64.whl
pip3 install torch_geometric/torch_sparse-0.6.14-cp310-cp310-linux_x86_64.whl
pip3 install torch_geometric/torch_spline_conv-1.2.1+pt112cpu-cp310-cp310-linux_x86_64.whl
```

#### 3.配置数据库

安装、配置mysql
https://blog.csdn.net/weixin_45626288/article/details/133220238

执行SQL:
```sql

CREATE TABLE IF NOT EXISTS detect_task (
    -- 主键，使用自增长整数类型作为主键，唯一标识每条记录
    id INT AUTO_INCREMENT PRIMARY KEY,
    -- 任务名，使用合适长度的可变长字符串类型，根据实际任务名长度预估来确定varchar长度，这里假设最长50个字符
    task_name VARCHAR(50) NOT NULL,
    -- netflow数据桶
    netflow_data_bucket VARCHAR(50) NOT NULL,
    -- netflow数据量，整型记录数据量情况
    netflow_data_count INT NOT NULL,
    -- netflow数据大小，以字节等单位衡量，使用整型记录
    netflow_data_size INT NOT NULL,
    -- netflow数据源起始时间，设置为timestamp类型，并添加索引方便按此时间查询
    netflow_data_source_start_time TIMESTAMP NOT NULL,
    -- 任务处理开始时间，timestamp类型记录任务何时开始处理
    task_processing_start_time TIMESTAMP NOT NULL,
    -- 预处理耗时，比如可以以秒为单位，使用浮点型记录耗时情况
    preprocessing_time FLOAT NOT NULL,
    -- 图构造耗时，同样以合适时间单位对应的数值类型记录，这里用浮点型示例
    graph_construction_time FLOAT NOT NULL,
    -- 图嵌入耗时，浮点型记录该阶段耗时
    graph_embedding_time FLOAT NOT NULL,
    -- 异常检测耗时，浮点型表示耗时长短
    anomaly_detection_time FLOAT NOT NULL,
    -- 异常检测结果，以字符串形式保存json序列化后的内容，使用较长的可变长字符串类型，根据实际可能的最长长度预估设置长度，这里假设最长5000字符
    anomaly_detection_result TEXT NOT NULL,
    -- 备用字段，以字符串形式保存其他相关信息，同样预估合适长度，这里假设最长2000字符
    extend TEXT NOT NULL,
    -- 创建时间，设置默认值为当前时间戳，插入记录时自动记录创建时间
    create_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    -- 更新时间，默认当前时间戳且在记录更新时自动更新该时间戳
    update_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

CREATE INDEX idx_netflow_data_source_start_time ON detect_task (netflow_data_source_start_time);
```

#### 4.运行

##### 4.1 配置config.yaml文件

```yaml
seed: 42 # 种子
model_dir: model # 模型保存路径
local_save: false # 是否本地输出
output_dir: data # 本地执行输出路径
percentage: 0.05 # 异常占比选择
data_source_type: reclone # 数据源配置类型
reclone_path: /iharbor/mahegu/t_fpc_flow_log_record # reclone数据源本地挂载路径
ftp_path: /t_fpc_flow_log_record # ftp数据源路径
train_data_len: 2  # 训练数据规模量

# f_dygat模型相关参数
f_dygat:
  epochs: 50
  learning_rate: 0.0001
  in_dim: 69
  out_dim: 32
  seq_len: 5
  flow_num: 1000

# maegan模型相关参数
maegan:
  n_epochs: 80
  in_dim: 64
  maxAE: 10
  batch_size: 64
  lr: 0.0001
  b1: 0.5
  b2: 0.9
  n_critic: 5

# mysql相关配置
mysql:
  host: '127.0.0.1'
  user: 'root'
  password: '123456'
  database: 'netflow'
  port: '3306'

ftp_server: "10.16.1.2"
ftp_user: "mahegu"
ftp_password: "6904b83623"
```

##### 4.2 训练
以近期的netflow数据进行训练

```Shell
python3 main.py --mode train
```

#### 4.3 实时推理
向crontab中添加命令：

```Shell
*/5 * * * * flock -n /tmp/netflow_anomaly.lockfile python3 /vdb2/NetFlowAnomaly/main.py
```